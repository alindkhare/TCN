{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba2e624",
   "metadata": {},
   "source": [
    "### TCN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e12a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            print(f\"TB[{i}] -> in_channels: {in_channels} out_channels: {out_channels}\")\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26d6dc",
   "metadata": {},
   "source": [
    "### TCN used for word-level PennTreebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc259a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, num_channels,\n",
    "                 kernel_size=2, dropout=0.3, emb_dropout=0.1, tied_weights=False):\n",
    "        super(TCN, self).__init__()\n",
    "        self.encoder = nn.Embedding(output_size, input_size)\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)\n",
    "\n",
    "        self.decoder = nn.Linear(num_channels[-1], output_size)\n",
    "        if tied_weights:\n",
    "            if num_channels[-1] != input_size:\n",
    "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "            print(\"Weight tied\")\n",
    "        self.drop = nn.Dropout(emb_dropout)\n",
    "        self.emb_dropout = emb_dropout\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.encoder.weight.data.normal_(0, 0.01)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input ought to have dimension (N, C_in, L_in), where L_in is the seq_len; here the input is (N, L, C)\"\"\"\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        y = self.tcn(emb.transpose(1, 2)).transpose(1, 2)\n",
    "        y = self.decoder(y)\n",
    "        return y.contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8990d",
   "metadata": {},
   "source": [
    "### Default settings for TCN on PennTreeBank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57af1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB[0] -> in_channels: 600 out_channels: 600\n",
      "TB[1] -> in_channels: 600 out_channels: 600\n",
      "TB[2] -> in_channels: 600 out_channels: 600\n",
      "TB[3] -> in_channels: 600 out_channels: 600\n",
      "Weight tied\n"
     ]
    }
   ],
   "source": [
    "# the first two configs are for the embedding layer. \n",
    "# We don't expect to dynamically change embedding layer\n",
    "# during weight-shared training.\n",
    "emsize = 600\n",
    "n_words = 10000\n",
    "### num_channels can be elastic\n",
    "nhid = 600\n",
    "levels = 4\n",
    "num_chans = [nhid]*(levels-1) + [emsize]\n",
    "dropout = 0.45\n",
    "emb_dropout = 0.25\n",
    "k_size = 3\n",
    "tied = True\n",
    "model = TCN(emsize, n_words, num_chans, dropout=dropout, emb_dropout=emb_dropout, kernel_size=k_size, tied_weights=tied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c2af3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCN(\n",
       "  (encoder): Embedding(10000, 600)\n",
       "  (tcn): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=600, out_features=10000, bias=True)\n",
       "  (drop): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3e98e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.tcn.network[0].net[0](torch.ones((1,600,32)))\n",
    "model.tcn.network[1].net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97214d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 20\n",
    "out_channel = 40\n",
    "kernel_size = 3\n",
    "stride=1\n",
    "dilation = 2 \n",
    "padding_val = (kernel_size-1) * dilation\n",
    "# temp =  TemporalBlock(in_channel, out_channel, kernel_size=kernel_size, stride=stride, dilation=dilation, padding=padding_val, dropout=0.45)\n",
    "tcn_conv = weight_norm(nn.Conv1d(in_channel, out_channel, kernel_size,\n",
    "                                           stride=stride, padding=padding_val, dilation=dilation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn_conv.weight_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bfd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, m in enumerate(temp.net.modules()):\n",
    "#     print(f\"ID: {idx} Module: {m}\")\n",
    "inp = torch.ones((1,20,32))\n",
    "out = tcn_conv(inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f4862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch import _weight_norm, norm_except_dim\n",
    "import torch.nn.functional as F\n",
    "from ofa.utils import get_same_padding\n",
    "\n",
    "class DynamicConv1dWtNorm(nn.Module):\n",
    "\tdef __init__(self, max_in_channels, max_out_channels, kernel_size=1, stride=1, dilation=1, padding=0, dim=0, weight_norm=True):\n",
    "\t\tsuper(DynamicConv1dWtNorm, self).__init__()\n",
    "\t\tself.max_in_channels = max_in_channels\n",
    "\t\tself.max_out_channels = max_out_channels\n",
    "\t\tself.kernel_size = kernel_size\n",
    "\t\tself.stride = stride\n",
    "\t\tself.dilation = dilation\n",
    "\t\tself.padding = padding\n",
    "\t\tself.conv = nn.Conv1d(self.max_in_channels, self.max_out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "\t\tweight = self.conv.weight\n",
    "\t\tself.dim = dim\n",
    "\t\tif weight_norm:\n",
    "\t\t\tself.conv_g =  Parameter(norm_except_dim(weight, 2, dim=self.dim).data)\n",
    "\t\t\tself.conv_v = Parameter(Parameter(weight.data))\n",
    "\t\tself.active_out_channel = self.max_out_channels\n",
    "\t\n",
    "\tdef get_active_filter(self, out_channel, in_channel):\n",
    "\t\tif weight_norm:\n",
    "\t\t\treturn _weight_norm(self.conv_v[:out_channel, :in_channel, :], self.conv_g[:out_channel, :, :], self.dim)\n",
    "\t\treturn self.conv.weight[:out_channel, :in_channel, :]\n",
    "\n",
    "\tdef forward(self, x, out_channel=None):\n",
    "\t\tif out_channel is None:\n",
    "\t\t\tout_channel = self.active_out_channel\n",
    "\t\tin_channel = x.size(1)\n",
    "\t\tfilters = self.get_active_filter(out_channel, in_channel).contiguous()\n",
    "  \n",
    "\t\ty = F.conv1d(x, filters, self.conv.bias[:out_channel], self.stride, self.padding , self.dilation, 1)\n",
    "\t\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6579306",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 20\n",
    "out_channel = 40\n",
    "kernel_size = 3\n",
    "stride=1\n",
    "dilation = 2 \n",
    "padding_val = (kernel_size-1) * dilation\n",
    "dynamic_layer = DynamicConv1dWtNorm(in_channel, out_channel, kernel_size,\n",
    "                                           stride=stride, padding=padding_val, dilation=dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84c3113f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 36])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.ones((1,12,32))\n",
    "dynamic_layer.active_out_channel = 10\n",
    "out = dynamic_layer(inp)\n",
    "\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb5a95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ofa.utils import make_divisible\n",
    "class DynamicTemporalBlock(nn.Module):\n",
    "    def __init__(self, maxin_channel, maxout_channel, kernel_size, stride, dilation, padding, dropout=0.2, expand_ratio_list=[1.0]):\n",
    "        super(DynamicTemporalBlock, self).__init__()\n",
    "        self.active_expand_ratio = max(expand_ratio_list)\n",
    "        self.active_out_channel = maxout_channel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding\n",
    "        self.dropout = dropout\n",
    "        max_middle_channel = self.active_middle_channels\n",
    "        self.conv1 = DynamicConv1dWtNorm(maxin_channel, max_middle_channel, kernel_size,stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.conv2 = DynamicConv1dWtNorm(max_middle_channel, maxout_channel, kernel_size,stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.downsample = DynamicConv1dWtNorm(maxin_channel, maxout_channel, 1, weight_norm=False) if maxin_channel != maxout_channel else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.conv1.conv.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.conv.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.conv.weight.data.normal_(0, 0.01)\n",
    "    \n",
    "    @property\n",
    "    def active_middle_channels(self):\n",
    "        return round(self.active_out_channel * self.active_expand_ratio)\n",
    "    \n",
    "    def get_active_subnet(self, in_channel, preserve_weight=True):\n",
    "        sub_layer = MyTemporalBlock(in_channel, self.active_out_channel, self.active_middle_channels, self.kernel_size, self.stride, self.dilation, self.padding, self.dropout, self.dim)\n",
    "        middle_channel = self.active_middle_channels\n",
    "        out_channel = self.active_out_channel\n",
    "        # TODO (alind): add proper selection mechanisms\n",
    "        sub_layer.conv1.conv_g.data.copy_(self.conv1.conv_g.data[:middle_channel, :, :])\n",
    "        sub_layer.conv1.conv_v.data.copy_(self.conv1.conv_v.data[:middle_channel, :in_channel, :])\n",
    "        sub_layer.conv1.conv.bias.data.copy_(self.conv1.conv.bias.data[:middle_channel])\n",
    "        \n",
    "        sub_layer.conv2.conv_g.data.copy_(self.conv2.conv_g.data[:out_channel, :, :])\n",
    "        sub_layer.conv2.conv_v.data.copy_(self.conv2.conv_v.data[:out_channel, :middle_channel, :])\n",
    "        sub_layer.conv2.conv.bias.data.copy_(self.conv2.conv.bias.data[:out_channel])\n",
    "        return sub_layer\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature_dim = self.active_middle_channels\n",
    "        self.conv1.active_out_channel = feature_dim\n",
    "        self.conv2.active_out_channel = self.active_out_channel\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.active_out_channel = self.active_out_channel\n",
    "            \n",
    "        out = self.conv1(x)\n",
    "        out = self.chomp1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.chomp2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        \n",
    "        return self.relu(out + res)\n",
    "        \n",
    "          \n",
    "\n",
    "class Conv1dWtNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, dim=0, weight_norm=True):\n",
    "        super(DynamicConv1dWtNorm, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding\n",
    "        self.conv = nn.Conv1d(self.in_channels, self.out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        weight = self.conv.weight\n",
    "        self.dim = dim\n",
    "        if weight_norm:\n",
    "            self.conv_g =  Parameter(norm_except_dim(weight, 2, dim=self.dim).data)\n",
    "            self.conv_v = Parameter(Parameter(weight.data))\n",
    "        self.active_out_channel = self.max_out_channels\n",
    "\n",
    "    def get_active_filter(self):\n",
    "        if weight_norm:\n",
    "            return _weight_norm(self.conv_v, self.conv_g, self.dim)\n",
    "        return self.conv.weight\n",
    "\n",
    "    def forward(self, x, out_channel=None):\n",
    "        if out_channel is None:\n",
    "            out_channel = self.active_out_channel\n",
    "        in_channel = x.size(1)\n",
    "        filters = self.get_active_filter(out_channel, in_channel).contiguous()\n",
    "\n",
    "        y = F.conv1d(x, filters, self.conv.bias, self.stride, self.padding , self.dilation, 1)\n",
    "        return y\n",
    "    \n",
    "class MyTemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, middle_channel, kernel_size, stride, dilation, padding, dropout=0.2, dim=0):\n",
    "        super(MyTemporalBlock, self).__init__()\n",
    "  \n",
    "        self.dim = dim\n",
    "        self.conv1 = Conv1dWtNorm(n_inputs, middle_channel, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "#         nn.Conv1d(n_inputs, middle_channel, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "#         self.conv1_g =  Parameter(norm_except_dim(self.conv1.weight, 2, dim=self.dim).data)\n",
    "#         self.conv1_v = Parameter(Parameter(self.conv1.weight.data))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        # copy three important things conv_g, conv_v\n",
    "        self.conv2 = Conv1dWtNorm(middle_channel, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "#         self.conv2_g =  Parameter(norm_except_dim(self.conv2.weight, 2, dim=self.dim).data)\n",
    "#         self.conv2_v = Parameter(Parameter(self.conv2.weight.data))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.init_weights()\n",
    "        self.conv2.init_weights()\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.chomp1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.chomp2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        \n",
    "        return self.relu(out + res)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            print(f\"TB[{i}] -> in_channels: {in_channels} out_channels: {out_channels}\")\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "05f64b7906baca6d55330d6abcbe3db47ed306498f514fc2398b11fdc1d4d907"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
