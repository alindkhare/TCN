{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba2e624",
   "metadata": {},
   "source": [
    "### TCN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e12a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            print(f\"TB[{i}] -> in_channels: {in_channels} out_channels: {out_channels}\")\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26d6dc",
   "metadata": {},
   "source": [
    "### TCN used for word-level PennTreebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc259a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, num_channels,\n",
    "                 kernel_size=2, dropout=0.3, emb_dropout=0.1, tied_weights=False):\n",
    "        super(TCN, self).__init__()\n",
    "        self.encoder = nn.Embedding(output_size, input_size)\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)\n",
    "\n",
    "        self.decoder = nn.Linear(num_channels[-1], output_size)\n",
    "        if tied_weights:\n",
    "            if num_channels[-1] != input_size:\n",
    "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "            print(\"Weight tied\")\n",
    "        self.drop = nn.Dropout(emb_dropout)\n",
    "        self.emb_dropout = emb_dropout\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.encoder.weight.data.normal_(0, 0.01)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input ought to have dimension (N, C_in, L_in), where L_in is the seq_len; here the input is (N, L, C)\"\"\"\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        y = self.tcn(emb.transpose(1, 2)).transpose(1, 2)\n",
    "        y = self.decoder(y)\n",
    "        return y.contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8990d",
   "metadata": {},
   "source": [
    "### Default settings for TCN on PennTreeBank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57af1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB[0] -> in_channels: 600 out_channels: 600\n",
      "TB[1] -> in_channels: 600 out_channels: 600\n",
      "TB[2] -> in_channels: 600 out_channels: 600\n",
      "TB[3] -> in_channels: 600 out_channels: 600\n",
      "Weight tied\n"
     ]
    }
   ],
   "source": [
    "# the first two configs are for the embedding layer. \n",
    "# We don't expect to dynamically change embedding layer\n",
    "# during weight-shared training.\n",
    "emsize = 600\n",
    "n_words = 10000\n",
    "### num_channels can be elastic\n",
    "nhid = 600\n",
    "levels = 4\n",
    "num_chans = [nhid]*(levels-1) + [emsize]\n",
    "dropout = 0.45\n",
    "emb_dropout = 0.25\n",
    "k_size = 3\n",
    "tied = True\n",
    "model = TCN(emsize, n_words, num_chans, dropout=dropout, emb_dropout=emb_dropout, kernel_size=k_size, tied_weights=tied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2af3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCN(\n",
       "  (encoder): Embedding(10000, 600)\n",
       "  (tcn): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): TemporalBlock(\n",
       "        (conv1): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.45, inplace=False)\n",
       "        (conv2): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.45, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.45, inplace=False)\n",
       "          (4): Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.45, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=600, out_features=10000, bias=True)\n",
       "  (drop): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3e98e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(600, 600, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.tcn.network[0].net[0](torch.ones((1,600,32)))\n",
    "model.tcn.network[1].net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97214d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 20\n",
    "out_channel = 40\n",
    "kernel_size = 3\n",
    "stride=1\n",
    "dilation = 2 \n",
    "padding_val = (kernel_size-1) * dilation\n",
    "# temp =  TemporalBlock(in_channel, out_channel, kernel_size=kernel_size, stride=stride, dilation=dilation, padding=padding_val, dropout=0.45)\n",
    "tcn_conv = weight_norm(nn.Conv1d(in_channel, out_channel, kernel_size,\n",
    "                                           stride=stride, padding=padding_val, dilation=dilation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn_conv.weight_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3bfd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6395,  0.6395,  0.5636,  ...,  0.8489,  0.9248,  0.9248],\n",
       "         [ 0.0329,  0.0329, -0.3584,  ..., -0.4991, -0.1079, -0.1079],\n",
       "         [ 0.2309,  0.2309,  0.4339,  ...,  0.2844,  0.0814,  0.0814],\n",
       "         ...,\n",
       "         [ 0.2028,  0.2028, -0.1882,  ..., -0.6475, -0.2564, -0.2564],\n",
       "         [-0.3380, -0.3380, -0.3536,  ..., -0.1350, -0.1194, -0.1194],\n",
       "         [ 0.2696,  0.2696,  0.6128,  ..., -0.3301, -0.6732, -0.6732]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for idx, m in enumerate(temp.net.modules()):\n",
    "#     print(f\"ID: {idx} Module: {m}\")\n",
    "inp = torch.ones((1,20,32))\n",
    "out = tcn_conv(inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "66f4862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch import _weight_norm, norm_except_dim\n",
    "import torch.nn.functional as F\n",
    "from ofa.utils import get_same_padding\n",
    "\n",
    "class DynamicConv1dWtNorm(nn.Module):\n",
    "\tdef __init__(self, max_in_channels, max_out_channels, kernel_size=1, stride=1, dilation=1, padding=0, dim=0, weight_norm=True):\n",
    "\t\tsuper(DynamicConv1dWtNorm, self).__init__()\n",
    "\t\tself.max_in_channels = max_in_channels\n",
    "\t\tself.max_out_channels = max_out_channels\n",
    "\t\tself.kernel_size = kernel_size\n",
    "\t\tself.stride = stride\n",
    "\t\tself.dilation = dilation\n",
    "\t\tself.padding = padding\n",
    "\t\tself.conv = nn.Conv1d(self.max_in_channels, self.max_out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "\t\tweight = self.conv.weight\n",
    "\t\tdel self.conv._parameters[\"weight\"]\n",
    "\t\tself.dim = dim\n",
    "\t\tif weight_norm:\n",
    "            # self.conv_g = Parameter(\n",
    "            #     norm_except_dim(weight, 2, dim=self.dim).data\n",
    "            # )\n",
    "            # self.conv_v = Parameter(Parameter(weight.data))\n",
    "           \n",
    "\t\t\tself.register_parameter(\"conv_g\", Parameter(\n",
    "\t\t\t\tnorm_except_dim(weight, 2, dim=self.dim).data\n",
    "\t\t\t))\n",
    "\t\t\tself.register_parameter(\"conv_v\",Parameter(weight.data) )\n",
    "\t\tself.active_out_channel = self.max_out_channels\n",
    "\t\n",
    "\tdef get_active_filter(self, out_channel, in_channel):\n",
    "\t\tif weight_norm:\n",
    "\t\t\treturn _weight_norm(self.conv_v[:out_channel, :in_channel, :], self.conv_g[:out_channel, :, :], self.dim)\n",
    "\t\treturn self.conv.weight[:out_channel, :in_channel, :]\n",
    "\n",
    "\tdef forward(self, x, out_channel=None):\n",
    "\t\tif out_channel is None:\n",
    "\t\t\tout_channel = self.active_out_channel\n",
    "\t\tin_channel = x.size(1)\n",
    "\t\tfilters = self.get_active_filter(out_channel, in_channel).contiguous()\n",
    "  \n",
    "\t\ty = F.conv1d(x, filters, self.conv.bias[:out_channel], self.stride, self.padding , self.dilation, 1)\n",
    "\t\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6579306",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 20\n",
    "out_channel = 40\n",
    "kernel_size = 3\n",
    "stride=1\n",
    "dilation = 2 \n",
    "padding_val = (kernel_size-1) * dilation\n",
    "dynamic_layer = DynamicConv1dWtNorm(in_channel, out_channel, kernel_size,\n",
    "                                           stride=stride, padding=padding_val, dilation=dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84c3113f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 36])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.ones((1,12,32))\n",
    "dynamic_layer.active_out_channel = 10\n",
    "out = dynamic_layer(inp)\n",
    "\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cb5a95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ofa.utils import make_divisible\n",
    "class DynamicTemporalBlock(nn.Module):\n",
    "    def __init__(self, maxin_channel, maxout_channel, kernel_size, stride, dilation, padding, dropout=0.2, expand_ratio_list=[1.0]):\n",
    "        super(DynamicTemporalBlock, self).__init__()\n",
    "        self.active_expand_ratio = max(expand_ratio_list)\n",
    "        self.expand_ratio_list = expand_ratio_list\n",
    "        self.active_out_channel = maxout_channel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding\n",
    "        self.dropout = dropout\n",
    "        max_middle_channel = self.active_middle_channels\n",
    "        self.conv1 = DynamicConv1dWtNorm(maxin_channel, max_middle_channel, kernel_size,stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.conv2 = DynamicConv1dWtNorm(max_middle_channel, maxout_channel, kernel_size,stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.downsample = DynamicConv1dWtNorm(maxin_channel, maxout_channel, 1, weight_norm=False) if maxin_channel != maxout_channel else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.conv1.conv.weight.data.normal_(0, 0.01)\n",
    "        # self.conv2.conv.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.conv.weight.data.normal_(0, 0.01)\n",
    "    \n",
    "    @property\n",
    "    def active_middle_channels(self):\n",
    "        return round(self.active_out_channel * self.active_expand_ratio)\n",
    "    \n",
    "    def get_active_subnet(self, in_channel, preserve_weight=True):\n",
    "        sub_layer = MyTemporalBlock(in_channel, self.active_out_channel, self.active_middle_channels, self.kernel_size, self.stride, self.dilation, self.padding, self.dropout)\n",
    "        middle_channel = self.active_middle_channels\n",
    "        out_channel = self.active_out_channel\n",
    "\n",
    "        sub_layer.conv1.conv_g.data.copy_(self.conv1.conv_g.data[:middle_channel, :, :])\n",
    "        sub_layer.conv1.conv_v.data.copy_(self.conv1.conv_v.data[:middle_channel, :in_channel, :])\n",
    "        sub_layer.conv1.conv.bias.data.copy_(self.conv1.conv.bias.data[:middle_channel])\n",
    "        \n",
    "        sub_layer.conv2.conv_g.data.copy_(self.conv2.conv_g.data[:out_channel, :, :])\n",
    "        sub_layer.conv2.conv_v.data.copy_(self.conv2.conv_v.data[:out_channel, :middle_channel, :])\n",
    "        sub_layer.conv2.conv.bias.data.copy_(self.conv2.conv.bias.data[:out_channel])\n",
    "        return sub_layer\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature_dim = self.active_middle_channels\n",
    "        self.conv1.active_out_channel = feature_dim\n",
    "        self.conv2.active_out_channel = self.active_out_channel\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.active_out_channel = self.active_out_channel\n",
    "            \n",
    "        out = self.conv1(x)\n",
    "        out = self.chomp1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.chomp2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        \n",
    "        return self.relu(out + res)\n",
    "        \n",
    "          \n",
    "\n",
    "class Conv1dWtNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, dim=0, weight_norm=True):\n",
    "        super(Conv1dWtNorm, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding\n",
    "        self.conv = nn.Conv1d(self.in_channels, self.out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        weight = self.conv.weight\n",
    "        del self.conv._parameters[\"weight\"]\n",
    "        self.dim = dim\n",
    "        if weight_norm:\n",
    "            # self.conv_g = Parameter(\n",
    "            #     norm_except_dim(weight, 2, dim=self.dim).data\n",
    "            # )\n",
    "            # self.conv_v = Parameter(Parameter(weight.data))\n",
    "           \n",
    "            self.register_parameter(\"conv_g\", Parameter(\n",
    "                norm_except_dim(weight, 2, dim=self.dim).data\n",
    "            ))\n",
    "            self.register_parameter(\"conv_v\",Parameter(weight.data) )\n",
    "        # self.active_out_channel = self.max_out_channels\n",
    "\n",
    "    def get_active_filter(self):\n",
    "        if weight_norm:\n",
    "            return _weight_norm(self.conv_v, self.conv_g, self.dim)\n",
    "        return self.conv.weight\n",
    "    \n",
    "    def init_weights(self):\n",
    "        pass\n",
    "        # self.conv.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x, out_channel=None):\n",
    "        # if out_channel is None:\n",
    "        #     out_channel = self.active_out_channel\n",
    "        # in_channel = x.size(1)\n",
    "        filters = self.get_active_filter().contiguous()\n",
    "\n",
    "        y = F.conv1d(x, filters, self.conv.bias, self.stride, self.padding , self.dilation, 1)\n",
    "        return y\n",
    "    \n",
    "class MyTemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, middle_channel, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(MyTemporalBlock, self).__init__()\n",
    "  \n",
    "        self.conv1 = Conv1dWtNorm(n_inputs, middle_channel, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        # copy three important things conv_g, conv_v\n",
    "        self.conv2 = Conv1dWtNorm(middle_channel, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.init_weights()\n",
    "        self.conv2.init_weights()\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.chomp1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.chomp2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        \n",
    "        return self.relu(out + res)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "02c9c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "from ofa.utils import val2list\n",
    "import random\n",
    "\n",
    "class MyTemporalConvNet(nn.Module):\n",
    "    def __init__(self, blocks):\n",
    "        super(MyTemporalConvNet, self).__init__()\n",
    "        self.blocks = blocks\n",
    "    \n",
    "    def eval(self):\n",
    "        for block in self.blocks:\n",
    "            block.eval()\n",
    "    \n",
    "    def train(self):\n",
    "        for block in self.blocks:\n",
    "            block.train()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        return out\n",
    "    \n",
    "class DynamicTemporalConvNet(nn.Module):\n",
    "    def __init__(self, input_channel, num_channels, kernel_size=2, dropout=0.2, depth_list = [2], expand_ratio_list=[0.25]):\n",
    "        super(DynamicTemporalConvNet, self).__init__()\n",
    "        self.runtime_depth = 0\n",
    "        self.max_depth = max(depth_list)\n",
    "        self.depth_list = depth_list\n",
    "        self.expand_ratio_list = expand_ratio_list\n",
    "        self.blocks = []\n",
    "        self.input_channel = input_channel\n",
    "        for i in range(len(num_channels)):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = input_channel if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            self.blocks += [DynamicTemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout, expand_ratio_list=self.expand_ratio_list)]\n",
    "    \n",
    "    def set_active_subnet(self, d=None, e=None, w=None):\n",
    "        # current elastic elasticTCN doesn't support width multipliers\n",
    "        if isinstance(d, list):\n",
    "            d = d[0]\n",
    "        expand_ratios = val2list(e, len(self.blocks))\n",
    "        for block, expand_ratio in zip(self.blocks, expand_ratios):\n",
    "            block.active_expand_ratio = expand_ratio\n",
    "        if d is not None:\n",
    "            self.runtime_depth = self.max_depth - d\n",
    "    \n",
    "    def eval(self):\n",
    "        for block in self.blocks:\n",
    "            block.eval()\n",
    "    \n",
    "    def train(self):\n",
    "        for block in self.blocks:\n",
    "            block.train()\n",
    "    \n",
    "    def set_max_net(self):\n",
    "        self.set_active_subnet(d=max(self.depth_list), e=max(self.expand_ratio_list), w=None)\n",
    "        \n",
    "    def sample_active_subnet(self):\n",
    "        # current elastic elasticTCN doesn't support width multipliers\n",
    "        expand_setting = []\n",
    "        for block in self.blocks:\n",
    "            expand_setting.append(random.choice(block.expand_ratio_list))\n",
    "        depth = random.choice(self.depth_list)\n",
    "        \n",
    "        arch_config = {\n",
    "            \"d\" : depth,\n",
    "            \"e\" : expand_setting,\n",
    "            \"w\" : None\n",
    "        }\n",
    "        self.set_active_subnet(**arch_config)\n",
    "        return arch_config\n",
    "    \n",
    "    def get_active_subnet(self):\n",
    "        blocks = []\n",
    "        input_channel = self.input_channel\n",
    "        for block in self.blocks[:len(self.blocks)-self.runtime_depth]:\n",
    "            blocks.append(block.get_active_subnet(in_channel=input_channel))\n",
    "            input_channel = block.active_out_channel\n",
    "        \n",
    "        return MyTemporalConvNet(blocks=blocks) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for block in self.blocks[:len(self.blocks)-self.runtime_depth]:\n",
    "            out = block(out)\n",
    "        return out\n",
    "\n",
    "class MyTCN(nn.Module):\n",
    "    def __init__(self, encoder, tcn, decoder, drop):\n",
    "        super(MyTCN, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.tcn = tcn\n",
    "        self.decoder = decoder\n",
    "        self.drop = drop\n",
    "    \n",
    "    def eval(self):\n",
    "        self.encoder.eval()\n",
    "        self.tcn.eval()\n",
    "        self.decoder.eval()\n",
    "        self.drop.eval()\n",
    "    \n",
    "    def train(self):\n",
    "        self.encoder.train()\n",
    "        self.tcn.train()\n",
    "        self.decoder.train()\n",
    "        self.drop.train()\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        y = self.tcn(emb.transpose(1, 2)).transpose(1, 2)\n",
    "        y = self.decoder(y)\n",
    "        return y.contiguous()\n",
    "        \n",
    "class ElasticTCN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, num_channels,\n",
    "                 kernel_size=2, dropout=0.3, emb_dropout=0.1, tied_weights=False, depth_list = [2], expand_ratio_list=[0.25]):\n",
    "        super(ElasticTCN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.encoder = nn.Embedding(output_size, input_size)\n",
    "        self.tcn = DynamicTemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout, depth_list=depth_list, expand_ratio_list=expand_ratio_list)\n",
    "        self.last_channel = num_channels[-1]\n",
    "\n",
    "        self.decoder = nn.Linear(num_channels[-1], output_size)\n",
    "        if tied_weights:\n",
    "            if num_channels[-1] != input_size:\n",
    "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "            print(\"Weight tied\")\n",
    "        self.drop = nn.Dropout(emb_dropout)\n",
    "        self.emb_dropout = emb_dropout\n",
    "        self.init_weights()\n",
    "\n",
    "    def eval(self):\n",
    "        self.encoder.eval()\n",
    "        self.tcn.eval()\n",
    "        self.decoder.eval()\n",
    "        self.drop.eval()\n",
    "    \n",
    "    def train(self):\n",
    "        self.encoder.train()\n",
    "        self.tcn.train()\n",
    "        self.decoder.train()\n",
    "        self.drop.train()\n",
    "        \n",
    "    def set_max_net(self):\n",
    "        self.tcn.set_max_net()\n",
    "    \n",
    "    def sample_active_subnet(self):\n",
    "        return self.tcn.sample_active_subnet()\n",
    "    \n",
    "    def set_active_subnet(self, d=None, e=None, w=None):\n",
    "        self.tcn.set_active_subnet(d=d, e=e, w=w)\n",
    "         \n",
    "    def get_active_subnet(self):\n",
    "        active_tcn = self.tcn.get_active_subnet()\n",
    "        encoder = nn.Embedding(self.output_size, self.input_size)\n",
    "        encoder.weight.data.copy_(self.encoder.weight.data)\n",
    "        decoder = nn.Linear(self.last_channel, self.output_size)\n",
    "        decoder.weight.data.copy_(self.decoder.weight.data)\n",
    "        decoder.bias.data.copy_(self.decoder.bias.data)\n",
    "\n",
    "        return MyTCN(\n",
    "            encoder, active_tcn, decoder, nn.Dropout(self.emb_dropout)\n",
    "        )\n",
    "    \n",
    "    \n",
    "     \n",
    "    def init_weights(self):\n",
    "        self.encoder.weight.data.normal_(0, 0.01)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input ought to have dimension (N, C_in, L_in), where L_in is the seq_len; here the input is (N, L, C)\"\"\"\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        y = self.tcn(emb.transpose(1, 2)).transpose(1, 2)\n",
    "        y = self.decoder(y)\n",
    "        return y.contiguous()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "76838ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight tied\n"
     ]
    }
   ],
   "source": [
    "emsize = 600\n",
    "n_words = 10000\n",
    "### num_channels can be elastic\n",
    "nhid = 600\n",
    "levels = 4\n",
    "num_chans = [nhid]*(levels-1) + [emsize]\n",
    "dropout = 0.45\n",
    "emb_dropout = 0.25\n",
    "k_size = 3\n",
    "tied = True\n",
    "depth_list = [0,1,2]\n",
    "expand_ratio_list = [0.1, 0.2, 0.25, 0.5, 1]\n",
    "model = ElasticTCN(emsize, n_words, num_chans, dropout=dropout, emb_dropout=emb_dropout, kernel_size=k_size, tied_weights=tied, depth_list=depth_list, expand_ratio_list=expand_ratio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b78c69bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': 1, 'e': [0.2, 0.5, 0.25, 0.2], 'w': None}\n"
     ]
    }
   ],
   "source": [
    "subnet_config = model.sample_active_subnet()\n",
    "print(subnet_config)\n",
    "subnet = model.get_active_subnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3233c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_max_net()\n",
    "max_subnet = model.get_active_subnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "41bcfa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = torch.ones((1,600), dtype=torch.long)\n",
    "model.set_max_net()\n",
    "max_subnet.eval()\n",
    "model.eval()\n",
    "torch.equal(max_subnet(input_sentence), model(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8caee8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet.eval()\n",
    "assert not torch.equal(max_subnet(input_sentence), subnet(input_sentence))\n",
    "assert not torch.equal(model(input_sentence), subnet(input_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b77bfda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_active_subnet(**subnet_config)\n",
    "model.eval()\n",
    "torch.equal(model(input_sentence), subnet(input_sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "05f64b7906baca6d55330d6abcbe3db47ed306498f514fc2398b11fdc1d4d907"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
